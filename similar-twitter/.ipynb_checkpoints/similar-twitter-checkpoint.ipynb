{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding Similar Users  on Twitter\n",
    "\n",
    "In this project we are trying to find similar users to a given user base on Twitter. The objective is to create a database of similar users around a topic.\n",
    "\n",
    "## Methodology\n",
    "\n",
    "We are mainly focusing on lists to find similar users. Here is the general process of the method:\n",
    "\n",
    "1. Determine base users. These users will underlie our similar user database. So it is important to choose users that are related to a common topic.\n",
    "2. Get base users' lists which they are a member of.\n",
    "3. Extract important specifications of the lists.\n",
    "4. Find common lists which all the base users are a member of.\n",
    "5. Eliminate some lists according to the subscriber_count and member_count of the lists.\n",
    "6. Get members of the common lists.\n",
    "7. Delete duplicate users and extract important information of users.\n",
    "8. From the obtained similar user list, determine accounts that are not human but big companies.\n",
    "9. Eliminate lists that includes determined big company accounts from the common lists.\n",
    "10. Finally, print out members of lastly obtained common lists.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Importing required libraries and Twitter API initializations\n",
    "\n",
    "We are using a Python library called birdy to access Twitter API. https://github.com/inueni/birdy\n",
    "\n",
    "To use birdy, key list must have consumer_key, consumer_secret, access_token_key, access_token_secret. More than one key configuration is recommended, to overcome API limits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "import datetime\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "from birdy.twitter import UserClient, BirdyException \n",
    "import numpy as np\n",
    "from time import sleep\n",
    "import pandas as pd\n",
    "\n",
    "key = []\n",
    "\n",
    "client = UserClient(key[0][0], key[0][1], key[0][2], key[0][3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Determining Base Users\n",
    "\n",
    "These users will underlie our similar user database. So it is important to choose users that are related to a common topic. Choosing users who is member of too much lists (generally users with more than 500k followers) can cause issues with Twitter API to not responding. So try to choose base users considering this issue. Highly possible that, the users with many followers will be in the base users' lists. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "users = ['karpathy','AndrewYNg','drfeifei','AlecRad','KirkDBorne', 'hmason', 'hadleywickham', ]\n",
    "\n",
    "# List preferences\n",
    "minSubscriber = 0\n",
    "maxMember = 500\n",
    "\n",
    "# User preferences\n",
    "minFollower = 1000\n",
    "minTweets = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Getting Base Users' Lists\n",
    "\n",
    "Getting base users' lists which they are a member of. Here we are using **\"GET lists/memberships\"** call to obtain lists. We are cycling around different API keys to overcome Rate Limit error and sleep(15) (waits 15 seconds) to Over Capacity error.\n",
    "\n",
    "We store all the lists in **userSubs** list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "karpathy\n",
      "AndrewYNg\n",
      "503\n",
      "Over capacity (GET https://api.twitter.com/1.1/lists/memberships.json?count=500&cursor=1546956732105377633&screen_name=AndrewYNg)\n",
      "503\n",
      "Over capacity (GET https://api.twitter.com/1.1/lists/memberships.json?count=500&cursor=1510900425542963537&screen_name=AndrewYNg)\n",
      "503\n",
      "Over capacity (GET https://api.twitter.com/1.1/lists/memberships.json?count=500&cursor=1510900425542963537&screen_name=AndrewYNg)\n",
      "503\n",
      "Over capacity (GET https://api.twitter.com/1.1/lists/memberships.json?count=500&cursor=1510900425542963537&screen_name=AndrewYNg)\n",
      "drfeifei\n",
      "AlecRad\n",
      "KirkDBorne\n",
      "503\n",
      "Over capacity (GET https://api.twitter.com/1.1/lists/memberships.json?count=500&cursor=1552010180382441804&screen_name=KirkDBorne)\n",
      "503\n",
      "Over capacity (GET https://api.twitter.com/1.1/lists/memberships.json?count=500&cursor=1541498369619755184&screen_name=KirkDBorne)\n",
      "503\n",
      "Over capacity (GET https://api.twitter.com/1.1/lists/memberships.json?count=500&cursor=1541498369619755184&screen_name=KirkDBorne)\n",
      "503\n",
      "Over capacity (GET https://api.twitter.com/1.1/lists/memberships.json?count=500&cursor=1530321515442206354&screen_name=KirkDBorne)\n",
      "503\n",
      "Over capacity (GET https://api.twitter.com/1.1/lists/memberships.json?count=500&cursor=1524640117541612673&screen_name=KirkDBorne)\n",
      "503\n",
      "Over capacity (GET https://api.twitter.com/1.1/lists/memberships.json?count=500&cursor=1524640117541612673&screen_name=KirkDBorne)\n",
      "hmason\n",
      "503\n",
      "Over capacity (GET https://api.twitter.com/1.1/lists/memberships.json?count=500&cursor=-1&screen_name=hmason)\n",
      "hadleywickham\n",
      "503\n",
      "Over capacity (GET https://api.twitter.com/1.1/lists/memberships.json?count=500&cursor=-1&screen_name=hadleywickham)\n"
     ]
    }
   ],
   "source": [
    "userSubs = []\n",
    "\n",
    "keyInd = 2\n",
    "client = UserClient(key[keyInd][0], key[keyInd][1], key[keyInd][2], key[keyInd][3])\n",
    "\n",
    "for user in users:\n",
    "    print(user)\n",
    "    protec = False\n",
    "    sub = []\n",
    "    \n",
    "    while(True):\n",
    "        try:\n",
    "            response = client.api.lists.memberships.get(screen_name=user, count=500, cursor=-1)\n",
    "            break\n",
    "        except Exception as err:\n",
    "            print(err.status_code)\n",
    "            print(err)\n",
    "            if err.status_code == 429:\n",
    "                sleep(60)\n",
    "                keyInd = (keyInd + 1)%len(key)\n",
    "            elif err.status_code == 404:\n",
    "                protec = True\n",
    "                break\n",
    "            else:\n",
    "                sleep(15)\n",
    "            \n",
    "            client = UserClient(key[keyInd][0], key[keyInd][1], key[keyInd][2], key[keyInd][3])\n",
    "            \n",
    "    if protec:\n",
    "        userSubs.append([])\n",
    "        print('protected!')\n",
    "        continue\n",
    "    ncur = response.data['next_cursor']\n",
    "    for s in response.data['lists']:\n",
    "        sub.append(s)\n",
    "    \n",
    "    while(ncur != 0):\n",
    "        while(True):\n",
    "            try:\n",
    "                response = client.api.lists.memberships.get(screen_name=user, count=500, cursor=ncur)\n",
    "                break\n",
    "            except Exception as err:\n",
    "                print(err.status_code)\n",
    "                print(err)\n",
    "                if err.status_code == 429:\n",
    "                    sleep(60)\n",
    "                    keyInd = (keyInd + 1)%len(key)\n",
    "                else:\n",
    "                    sleep(15)\n",
    "                client = UserClient(key[keyInd][0], key[keyInd][1], key[keyInd][2], key[keyInd][3])\n",
    "        \n",
    "        ncur = response.data['next_cursor']\n",
    "        for s in response.data['lists']:\n",
    "            sub.append(s)\n",
    "            \n",
    "    userSubs.append(sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Extract important specifications of the lists\n",
    "\n",
    "The extracted specifications with examples:\n",
    "* **name:**\t\t\t\t\"Digital Marketing\"\n",
    "* **slug:** \t\t\t\"digital-marketing\"\n",
    "* **id:** \t\t\t\t49260625\n",
    "* **full_name:**\t\t\"@pointcg/digital-marketing\"\n",
    "* **subscriber_count:** 1\n",
    "* **member_count:**\t\t46\n",
    "\n",
    "**userLists** list holds the lists with specs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('My AI', 'my-ai', '862370344073560064', '@intellification/my-ai', 0, 8)\n"
     ]
    }
   ],
   "source": [
    "# 0. \"name\": \"Digital Marketing\"\n",
    "# 1. \"slug\": \"digital-marketing\"\n",
    "# 2. \"id\": 49260625\n",
    "# 3. \"full_name\": \"@pointcg/digital-marketing\"\n",
    "# 4. \"subscriber_count\": 1\n",
    "# 5. \"member_count\": 46\n",
    "\n",
    "userLists = []\n",
    "\n",
    "for userSub in userSubs:\n",
    "    ul = []\n",
    "    for li in userSub:\n",
    "        ul.append((li['name'], li['slug'], str(li['id']), li['full_name'], li['subscriber_count'], li['member_count']))\n",
    "        \n",
    "    userLists.append(ul)\n",
    "    \n",
    "print(userLists[0][5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Find Common Lists\n",
    "\n",
    "Finds common lists which all the base users are a member of and stores it in **commonLists** list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of common lists: 11\n"
     ]
    }
   ],
   "source": [
    "#commonLists = []\n",
    "\n",
    "#for li in userLists[0]:\n",
    "#    if li in userLists[1]:\n",
    "#        commonLists.append(li)\n",
    "\n",
    "commonLists = list(userLists[0])\n",
    "\n",
    "for cL in commonLists[:]:\n",
    "    for uL in userLists[1:]:\n",
    "        if cL not in uL:\n",
    "            commonLists.remove(cL)\n",
    "            break\n",
    "\n",
    "print(\"Number of common lists: \" + str(len(commonLists)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Eliminate some lists according to the subscriber_count and member_count of the lists from Common Lists\n",
    "\n",
    "First, we are sorting the Common Lists according to subscriber_count to process easily. Then we are choosing lists that have at least 10 subscriber and at most 300 members. Those values are experimental. Stored in **mostCommons** list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Name                 Slug                  ID  \\\n",
      "0       machine learning     machine-learning           205125841   \n",
      "1  AI & machine learning  ai-machine-learning           231045220   \n",
      "2              analytics            analytics  820723315467833344   \n",
      "3                   data                 data  742832583449382912   \n",
      "\n",
      "                         Fullname  Subscribers  Members  \n",
      "0    @inancgumus/machine-learning            4      408  \n",
      "1  @voxmenthe/ai-machine-learning            2      352  \n",
      "2            @_mokhtar_/analytics            1      314  \n",
      "3                 @AlanJumpi/data            0      218  \n",
      "\n",
      "Number of common lists after elimination: 4\n",
      "Number of members in lists: 1292\n"
     ]
    }
   ],
   "source": [
    "commonLists = sorted(commonLists,key=lambda x: x[4], reverse=True)\n",
    "\n",
    "mostCommons = []\n",
    "\n",
    "totalMember = 0\n",
    "for li in commonLists:\n",
    "    # List subscriber >= 0 and List member < 300\n",
    "    if li[4] >= minSubscriber and li[5] < maxMember:\n",
    "        totalMember = totalMember + li[5]\n",
    "        mostCommons.append(li)\n",
    "        \n",
    "df = pd.DataFrame(columns=('Name', 'Slug', 'ID', 'Fullname', 'Subscribers', 'Members'))\n",
    "pd.options.display.float_format = '{:,.0f}'.format\n",
    "for i in range(len(mostCommons)):\n",
    "    df.loc[i] = mostCommons[i]\n",
    "\n",
    "print(df)\n",
    "\n",
    "print()\n",
    "print(\"Number of common lists after elimination: \" + str(len(mostCommons)))\n",
    "print(\"Number of members in lists: \" + str(totalMember)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Get members of the common lists\n",
    "\n",
    "Here we are using **\"GET lists/members\"** call to obtain users of each lists. We are again cycling around different API keys to overcome Rate Limit error and sleep(15) (waits 15 seconds) to Over Capacity error.\n",
    "\n",
    "We store all the users in **similarUsers** list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('machine learning', 'machine-learning', '205125841', '@inancgumus/machine-learning', 4, 408)\n",
      "('AI & machine learning', 'ai-machine-learning', '231045220', '@voxmenthe/ai-machine-learning', 2, 352)\n",
      "('analytics', 'analytics', '820723315467833344', '@_mokhtar_/analytics', 1, 314)\n",
      "('data', 'data', '742832583449382912', '@AlanJumpi/data', 0, 218)\n"
     ]
    }
   ],
   "source": [
    "client = UserClient(key[keyInd][0], key[keyInd][1], key[keyInd][2], key[keyInd][3])\n",
    "\n",
    "similarUsers = []\n",
    "\n",
    "for li in mostCommons:\n",
    "    print(li)\n",
    "    sims = []\n",
    "    \n",
    "    while(True):\n",
    "        try:\n",
    "            response = client.api.lists.members.get(list_id=li[2], count=1000, cursor=-1)\n",
    "            break\n",
    "        except Exception as err:\n",
    "            print(err.status_code)\n",
    "            print(err)\n",
    "            if err.status_code == 429:\n",
    "                sleep(60)\n",
    "                keyInd = (keyInd + 1)%len(key)\n",
    "            else:\n",
    "                sleep(15)\n",
    "            client = UserClient(key[keyInd][0], key[keyInd][1], key[keyInd][2], key[keyInd][3])\n",
    "            #response = client.api.lists.members.get(list_id=li[2], count=1000, cursor=-1)\n",
    "    \n",
    "    \n",
    "    ncur = response.data['next_cursor']\n",
    "    for s in response.data['users']:\n",
    "        sims.append(s)\n",
    "    \n",
    "    while(ncur != 0):\n",
    "        while(True):                \n",
    "            try:\n",
    "                response = client.api.lists.members.get(list_id=li[2], count=1000, cursor=ncur)\n",
    "                break\n",
    "            except Exception as err:\n",
    "                print(err.status_code)\n",
    "                print(err)\n",
    "                if err.status_code == 429:\n",
    "                    sleep(60)\n",
    "                    keyInd = (keyInd + 1)%len(key)\n",
    "                else:\n",
    "                    sleep(15)\n",
    "                client = UserClient(key[keyInd][0], key[keyInd][1], key[keyInd][2], key[keyInd][3])\n",
    "                #response = client.api.lists.members.get(list_id=li[2], count=1000, cursor=ncur)\n",
    "        \n",
    "        \n",
    "        ncur = response.data['next_cursor']\n",
    "        for s in response.data['users']:\n",
    "            sims.append(s)\n",
    "            \n",
    "    similarUsers.append(sims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Delete duplicate users and extract important information of users.\n",
    "\n",
    "Important specifications of users:\n",
    "* **id_str**\t\t\t\t: ID of the user\n",
    "* **screen_name**\t\t: Screen name of the user (@screen_name)\n",
    "* **followers_count**\t: # Followers\n",
    "* **friends_count**\t\t: # Following\n",
    "* **favourites_count**\t: # Likes\n",
    "* **listed_count**\t\t: Total number of list subscription and membership (?)\n",
    "* **statuses_count**\t\t: # Tweets\n",
    "* **verified**\t\t\t: True or False \n",
    "* **protected**\t\t\t: True or False / if true can't crawl the account\n",
    "* **created_at**\t\t\t: Creation time of the account / (2009-10-30 12:11:39)\n",
    "\n",
    "**similars** list holds the users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique users: 1072\n"
     ]
    }
   ],
   "source": [
    "# 0. id_str\t\t\t\t: ID of the user\n",
    "# 1. screen_name\t\t: Screen name of the user (@screen_name)\n",
    "# 2. followers_count\t: # Followers\n",
    "# 3. friends_count\t\t: # Following\n",
    "# 4. favourites_count\t: # Likes\n",
    "# 5. listed_count\t\t: Total number of list subscription and membership (?)\n",
    "# 6. statuses_count\t\t: # Tweets\n",
    "# 7. verified\t\t\t: True or False \n",
    "# 8. protected\t\t\t: True or False / if true can't crawl the account\n",
    "# 9. created_at\t\t\t: Creation time of the account / (2009-10-30 12:11:39)\n",
    "\n",
    "similars = []\n",
    "uNames = []\n",
    "for sus in similarUsers:\n",
    "    for su in sus:\n",
    "        if su['screen_name'] not in uNames:\n",
    "            uNames.append(su['screen_name'])\n",
    "            similars.append((su['id_str'], su['screen_name'], su['followers_count'], su['friends_count'],\n",
    "                          su['favourites_count'], su['listed_count'], su['statuses_count'], su['verified'], \n",
    "                          su['protected'], su['created_at']))\n",
    "            \n",
    "print(\"Number of unique users: \" + str(len(similars)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. From the obtained similar user list, determine accounts that are not human but big companies.\n",
    "\n",
    "First we sort similar users according to followers_count, then observe those users to determine not human but big company accounts.\n",
    "\n",
    "Here we only printed out the top 20 accounts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "567\n",
      "            ID             Name  Followers  Friends  Favourites  Listed  \\\n",
      "0     16017475    NateSilver538  2,249,956      985         132  27,834   \n",
      "1     33838201   googleresearch  1,107,765       19           0  12,474   \n",
      "2     51263711  googleanalytics  1,006,549      404       2,755  18,292   \n",
      "3     34181507  dez_blanchfield    754,646      472      14,339   1,519   \n",
      "4   1526228120      TwitterData    735,709       10          17   4,195   \n",
      "5     20280065      HansRosling    372,773      172         177   6,158   \n",
      "6     18080585          MongoDB    271,918    5,480       2,354   4,864   \n",
      "7    259725229       ValaAfshar    189,276      440           2   9,165   \n",
      "8     15662446          avinash    182,407       88          14  11,432   \n",
      "9     14174897   analyticbridge    160,818    4,377       5,895   5,946   \n",
      "10   267283568       IBMBigData    153,333    2,148       4,458   4,370   \n",
      "11   198483889        dr_morton    150,534   95,326      61,733   6,523   \n",
      "12    54645160            DARPA    150,279    3,254       1,657   4,997   \n",
      "13   534563976       KirkDBorne    150,159   76,925     109,182   6,403   \n",
      "14   227423290     simonlporter    135,569  108,090      41,429   5,648   \n",
      "15   288500051      hortonworks    127,651      368         682   1,586   \n",
      "16   216939636        AndrewYNg    124,925      244         362   3,144   \n",
      "17  2813668064   GreatAnalytics    122,754    1,549       3,526     212   \n",
      "18    17350542      Informatica    117,810      905         806   2,676   \n",
      "19   201846344         IBMcloud    116,770    3,345       3,054   2,762   \n",
      "\n",
      "    Statuses Verified Protected                      Created_at  \n",
      "0     15,996     True     False  Wed Aug 27 20:56:45 +0000 2008  \n",
      "1        958     True     False  Tue Apr 21 06:59:33 +0000 2009  \n",
      "2      6,685     True     False  Fri Jun 26 22:55:52 +0000 2009  \n",
      "3     44,787    False     False  Wed Apr 22 04:24:37 +0000 2009  \n",
      "4      1,315     True     False  Mon Jun 17 23:57:45 +0000 2013  \n",
      "5      3,929     True     False  Fri Feb 06 22:54:12 +0000 2009  \n",
      "6     12,954     True     False  Fri Dec 12 17:21:18 +0000 2008  \n",
      "7    309,124     True     False  Wed Mar 02 13:31:29 +0000 2011  \n",
      "8     17,455     True     False  Wed Jul 30 16:40:56 +0000 2008  \n",
      "9     94,954    False     False  Wed Mar 19 05:26:29 +0000 2008  \n",
      "10    40,760     True     False  Wed Mar 16 17:05:33 +0000 2011  \n",
      "11   166,732    False     False  Mon Oct 04 12:55:19 +0000 2010  \n",
      "12     4,368     True     False  Tue Jul 07 19:13:34 +0000 2009  \n",
      "13    71,021    False     False  Fri Mar 23 16:35:17 +0000 2012  \n",
      "14   288,011    False     False  Thu Dec 16 20:20:15 +0000 2010  \n",
      "15     8,150     True     False  Tue Apr 26 23:42:17 +0000 2011  \n",
      "16       903     True     False  Thu Nov 18 03:39:11 +0000 2010  \n",
      "17     1,192    False     False  Tue Sep 16 20:41:27 +0000 2014  \n",
      "18    21,010     True     False  Wed Nov 12 22:26:04 +0000 2008  \n",
      "19    34,661     True     False  Tue Oct 12 19:11:21 +0000 2010  \n"
     ]
    }
   ],
   "source": [
    "sortedSimilars = sorted(similars,key=lambda x: x[2], reverse=True)\n",
    "\n",
    "chosens = []\n",
    "\n",
    "for s in sortedSimilars:\n",
    "    if s[2] < minFollower:\n",
    "        break\n",
    "    if s[6] > minTweets and s[2] > s[3] and s[8] == False:\n",
    "        chosens.append(s)\n",
    "        \n",
    "df = pd.DataFrame(columns=('ID', 'Name', 'Followers', 'Friends', 'Favourites', 'Listed', 'Statuses', 'Verified', 'Protected', 'Created_at'))\n",
    "pd.options.display.float_format = '{:,.0f}'.format\n",
    "for i in range(20):\n",
    "    df.loc[i] = chosens[i]\n",
    "\n",
    "print(len(chosens))\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of remaining lists after elimination: 4\n"
     ]
    }
   ],
   "source": [
    "goodLists = []\n",
    "badUsers = []\n",
    "#badUsers = ['cnnbrk', 'nytimes', 'CNN', 'BBCBreaking', 'TheEconomist', 'BBCWorld', 'Reuters', 'FoxNews', 'TIME', 'WSJ',\n",
    "#            'Forbes', 'ABC', 'HuffPost', 'washingtonpost']\n",
    "\n",
    "for i in range(len(similarUsers)):\n",
    "    bad = False\n",
    "    for su in similarUsers[i]:\n",
    "        if su['screen_name'] in badUsers:\n",
    "            bad = True\n",
    "            break\n",
    "    if not bad:\n",
    "        goodLists.append(i)\n",
    "\n",
    "print(\"Number of remaining lists after elimination: \" + str(len(goodLists)))\n",
    "#print(goodLists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Eliminate lists that includes determined big company accounts from the common lists.\n",
    "\n",
    "Eliminate lists that includes determined big company accounts from the common lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Name                 Slug                  ID  \\\n",
      "0       machine learning     machine-learning           205125841   \n",
      "1  AI & machine learning  ai-machine-learning           231045220   \n",
      "2              analytics            analytics  820723315467833344   \n",
      "3                   data                 data  742832583449382912   \n",
      "\n",
      "                         Fullname  Subscribers  Members  \n",
      "0    @inancgumus/machine-learning            4      408  \n",
      "1  @voxmenthe/ai-machine-learning            2      352  \n",
      "2            @_mokhtar_/analytics            1      314  \n",
      "3                 @AlanJumpi/data            0      218  \n",
      "\n",
      "Number of common lists after elimination: 4\n",
      "Number of members in lists: 1292\n"
     ]
    }
   ],
   "source": [
    "similarUsers2 = []\n",
    "\n",
    "totalMember = 0\n",
    "\n",
    "for i in goodLists:\n",
    "    if mostCommons[i][4] >= minSubscriber and mostCommons[i][5] < maxMember:\n",
    "        totalMember = totalMember + mostCommons[i][5]\n",
    "        similarUsers2.append(similarUsers[i])\n",
    "\n",
    "df = pd.DataFrame(columns=('Name', 'Slug', 'ID', 'Fullname', 'Subscribers', 'Members'))\n",
    "pd.options.display.float_format = '{:,.0f}'.format\n",
    "for i in range(len(goodLists)):\n",
    "    if mostCommons[i][4] >= minSubscriber and mostCommons[i][5] < maxMember:\n",
    "        df.loc[i] = mostCommons[goodLists[i]]\n",
    "\n",
    "print(df)\n",
    "        \n",
    "print()\n",
    "print(\"Number of common lists after elimination: \" + str(len(similarUsers2)))\n",
    "print(\"Number of members in lists: \" + str(totalMember))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get members of the remaining common lists. Last remaining similar users are stored in **similars2**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique users: 1072\n"
     ]
    }
   ],
   "source": [
    "# 0. id_str\t\t\t\t: ID of the user\n",
    "# 1. screen_name\t\t: Screen name of the user (@screen_name)\n",
    "# 2. followers_count\t: # Followers\n",
    "# 3. friends_count\t\t: # Following\n",
    "# 4. favourites_count\t: # Likes\n",
    "# 5. listed_count\t\t: Total number of list subscription and membership (?)\n",
    "# 6. statuses_count\t\t: # Tweets\n",
    "# 7. verified\t\t\t: True or False \n",
    "# 8. protected\t\t\t: True or False / if true can't crawl the account\n",
    "# 9. created_at\t\t\t: Creation time of the account / (2009-10-30 12:11:39)\n",
    "\n",
    "similars2 = []\n",
    "uNames2 = []\n",
    "for sus in similarUsers2:\n",
    "    for su in sus:\n",
    "        if su['screen_name'] not in uNames2:\n",
    "            uNames2.append(su['screen_name'])\n",
    "            similars2.append((su['id_str'], su['screen_name'], su['followers_count'], su['friends_count'],\n",
    "                          su['favourites_count'], su['listed_count'], su['statuses_count'], su['verified'], \n",
    "                          su['protected'], su['created_at']))\n",
    "            \n",
    "\n",
    "print(\"Number of unique users: \" + str(len(similars2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Print out members of lastly obtained common lists.\n",
    "\n",
    "Finally, we are printing the similar users that we obtained. We use a simple filter to eliminate users with followers_count < 1500 and statuses_count < 250. Here we again only printed out the top 20 accounts' information. You can find all users in **\"SimilarUsers.txt\"** where we write all users' informations to. First line of **\"SimilarUsers.txt\"** includes base users' screen names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of similar users: 567\n",
      "\n",
      "            ID             Name  Followers  Friends  Favourites  Listed  \\\n",
      "0     16017475    NateSilver538  2,249,956      985         132  27,834   \n",
      "1     33838201   googleresearch  1,107,765       19           0  12,474   \n",
      "2     51263711  googleanalytics  1,006,549      404       2,755  18,292   \n",
      "3     34181507  dez_blanchfield    754,646      472      14,339   1,519   \n",
      "4   1526228120      TwitterData    735,709       10          17   4,195   \n",
      "5     20280065      HansRosling    372,773      172         177   6,158   \n",
      "6     18080585          MongoDB    271,918    5,480       2,354   4,864   \n",
      "7    259725229       ValaAfshar    189,276      440           2   9,165   \n",
      "8     15662446          avinash    182,407       88          14  11,432   \n",
      "9     14174897   analyticbridge    160,818    4,377       5,895   5,946   \n",
      "10   267283568       IBMBigData    153,333    2,148       4,458   4,370   \n",
      "11   198483889        dr_morton    150,534   95,326      61,733   6,523   \n",
      "12    54645160            DARPA    150,279    3,254       1,657   4,997   \n",
      "13   534563976       KirkDBorne    150,159   76,925     109,182   6,403   \n",
      "14   227423290     simonlporter    135,569  108,090      41,429   5,648   \n",
      "15   288500051      hortonworks    127,651      368         682   1,586   \n",
      "16   216939636        AndrewYNg    124,925      244         362   3,144   \n",
      "17  2813668064   GreatAnalytics    122,754    1,549       3,526     212   \n",
      "18    17350542      Informatica    117,810      905         806   2,676   \n",
      "19   201846344         IBMcloud    116,770    3,345       3,054   2,762   \n",
      "\n",
      "    Statuses Verified Protected                      Created_at  \n",
      "0     15,996     True     False  Wed Aug 27 20:56:45 +0000 2008  \n",
      "1        958     True     False  Tue Apr 21 06:59:33 +0000 2009  \n",
      "2      6,685     True     False  Fri Jun 26 22:55:52 +0000 2009  \n",
      "3     44,787    False     False  Wed Apr 22 04:24:37 +0000 2009  \n",
      "4      1,315     True     False  Mon Jun 17 23:57:45 +0000 2013  \n",
      "5      3,929     True     False  Fri Feb 06 22:54:12 +0000 2009  \n",
      "6     12,954     True     False  Fri Dec 12 17:21:18 +0000 2008  \n",
      "7    309,124     True     False  Wed Mar 02 13:31:29 +0000 2011  \n",
      "8     17,455     True     False  Wed Jul 30 16:40:56 +0000 2008  \n",
      "9     94,954    False     False  Wed Mar 19 05:26:29 +0000 2008  \n",
      "10    40,760     True     False  Wed Mar 16 17:05:33 +0000 2011  \n",
      "11   166,732    False     False  Mon Oct 04 12:55:19 +0000 2010  \n",
      "12     4,368     True     False  Tue Jul 07 19:13:34 +0000 2009  \n",
      "13    71,021    False     False  Fri Mar 23 16:35:17 +0000 2012  \n",
      "14   288,011    False     False  Thu Dec 16 20:20:15 +0000 2010  \n",
      "15     8,150     True     False  Tue Apr 26 23:42:17 +0000 2011  \n",
      "16       903     True     False  Thu Nov 18 03:39:11 +0000 2010  \n",
      "17     1,192    False     False  Tue Sep 16 20:41:27 +0000 2014  \n",
      "18    21,010     True     False  Wed Nov 12 22:26:04 +0000 2008  \n",
      "19    34,661     True     False  Tue Oct 12 19:11:21 +0000 2010  \n"
     ]
    }
   ],
   "source": [
    "lastSimilars = []\n",
    "\n",
    "sortedSimilars2 = sorted(similars2,key=lambda x: x[2], reverse=True)\n",
    "\n",
    "f = open(\"SimilarUsers.txt\", 'w', encoding='utf-8')\n",
    "\n",
    "f.write(users[0])\n",
    "for u in users[1:]:\n",
    "    f.write(\",\" + u)\n",
    "f.write(\"\\n\")\n",
    "\n",
    "f.write(str(len(goodLists)))\n",
    "f.write(\"\\n\")\n",
    "for i in range(len(goodLists)):\n",
    "    f.write(str(mostCommons[goodLists[i]][0])+','+str(mostCommons[goodLists[i]][1])+','+str(mostCommons[goodLists[i]][2])+','\n",
    "          +str(mostCommons[goodLists[i]][3])+','+str(mostCommons[goodLists[i]][4])+','+str(mostCommons[goodLists[i]][5]))\n",
    "    f.write(\"\\n\")\n",
    "\n",
    "for s in sortedSimilars2:\n",
    "    if s[2] < minFollower:\n",
    "        break\n",
    "    if s[6] > minTweets and s[2] > s[3] and s[8] == False:\n",
    "        lastSimilars.append(s)\n",
    "        f.write(s[0] + ',' + s[1] + ',' + str(s[2]) + ',' + str(s[3]) + ',' + str(s[4]) + ',' + str(s[5]) + ',' + str(s[6])\n",
    "                + ',' + str(s[7]) + ',' + str(s[8]) + ',' + str(s[9]))\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "f.close()\n",
    "\n",
    "print(\"Number of similar users: \" + str(len(lastSimilars)))\n",
    "print()\n",
    "\n",
    "df = pd.DataFrame(columns=('ID', 'Name', 'Followers', 'Friends', 'Favourites', 'Listed', 'Statuses', 'Verified', 'Protected', 'Created_at'))\n",
    "pd.options.display.float_format = '{:,.0f}'.format\n",
    "for i in range(20):\n",
    "    df.loc[i] = lastSimilars[i]\n",
    "\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
